<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Welcome to the homepage of AutoRefine">
  <meta name="keywords" content="Deep Search, Large Language Models, Reinforcement Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Homepage of AutoRefine</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <link rel="stylesheet" href="./static/css/index-gradio.css">
  <link rel="stylesheet" href="./static/css/live_theme.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"
              style="display: flex;flex-direction: row;align-items: center;justify-content: center;margin-bottom: 5px;">Search and Refine During Think:</h1>
          <h1 class="title is-2 publication-title">Autonomous Retrieval‑Augmented Reasoning of LLMs</h1>
          <div class="is-size-5 publication-authors">
            Yaorui Shi, Sihang Li, Chang Wu, Zhiyuan Liu, Junfeng Fang, Hengxing Cai, An Zhang, Xiang Wang
            <span class="author-block"> <a href="https://scholar.google.com/citations?user=EWU3rdIAAAAJ&hl=en">Yaorui Shi</a><sup>1*</sup>,</span>
            <span class="author-block"> <a href="https://scholar.google.com/citations?user=1uFZs6EAAAAJ&hl=en">Sihang Li</a><sup>1*</sup>,</span>
            <span class="author-block"> Chang Wu<sup>1</sup>,</span>
            <span class="author-block"> Zhiyuan Liu<sup>2</sup>,</span>
            <span class="author-block"> Junfeng Fang<sup>2</sup>,</span>
            <span class="author-block"> <a href="https://scholar.google.com/citations?user=98SL3jMAAAAJ&hl=en">Hengxing Cai</a><sup>3†</sup>,</span>
            <span class="author-block"> An Zhang<sup>1</sup>,</span>
            <span class="author-block"> <a href="https://xiangwang1223.github.io">Xiang Wang</a><sup>1†</sup>,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Science and Technology of China</span>
            <br>
            <span class="author-block"><sup>2</sup>National University of Singapore</span>
            <span class="author-block"><sup>3</sup>DP Technology</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block" style="font-size: 15px;"><sup>*</sup>Equal Contribution</span>
            <span class="author-block" style="font-size: 15px;"><sup>†</sup>Correspondence</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2505.11277"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/syr-cn/AutoRefine"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Checkpoints. -->
              <span class="link-block">
                <a href="https://huggingface.co/yrshi/AutoRefine-Qwen2.5-3B-Base"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-database"></i>
                  </span>
                  <span>Checkpoints</span>
                  </a>
              </span>
              <!-- Demo Link. -->
              <!-- <span class="link-block">
                <a href="https://huggingface.co/spaces/yrshi/ReactXT"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-laugh-wink"></i>
                  </span>
                  <span>Demo</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://osf.io/3dv4k"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fa fa-database"></i>
                  </span>
                  <span>Dataset</span>
                  </a>
              </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large language models have demonstrated impressive reasoning capabilities but are inherently limited by their knowledge reservoir. Retrieval-augmented reasoning mitigates this limitation by allowing LLMs to query external resources, but existing methods often retrieve irrelevant or noisy information, hindering accurate reasoning. In this paper, we propose AutoRefine, a reinforcement learning post-training framework that adopts a new <b>"search-and-refine-during-think"</b> paradigm. AutoRefine introduces <u>explicit knowledge refinement steps</u> between successive search calls, enabling the model to iteratively filter, distill, and organize evidence before generating an answer. Furthermore, we incorporate tailored <u>retrieval-specific rewards</u> alongside answer correctness rewards using group relative policy optimization. Experiments on single-hop and multi-hop QA benchmarks demonstrate that AutoRefine significantly outperforms existing approaches, particularly in complex, multi-hop reasoning scenarios. Detailed analysis shows that AutoRefine issues frequent, higher-quality searches and synthesizes evidence effectively.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <br>
    </div>
    <img class="columns is-centered has-text-centered framework" src="./static/images/radar_plot.jpg" alt="Teaser" width="100%" style="margin:0 auto">
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">

    <!-- Limitatoins. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-2">Research Gaps</h2>
        <div class="columns is-centered">
          <div class="column is-full-width">
              <div class="content has-text-justified">
                  <img class="columns is-centered has-text-centered framework" src="./static/images/innovations.jpg" alt="innovation" width="100%" style="margin:0 auto">
                  <br>
                  <p>
                    Current retrieval-augmented reasoning approaches face two key limitations:
                    <ul>
                      <li><b>Lack of refinement of retrieved documents:</b> Existing methods typically feed retrieved documents directly to the LLM without first distilling key information. This forces LLMs to process large volumes of potentially irrelevant content, making it difficult to identify and focus on the most relevant knowledge.</li>
                      <li><b>Underexplored retrieval-specific rewards:</b> Most reinforcement learning-based RAG methods rely solely on outcome-based rewards (like answer correctness) to guide the model's behavior. They neglect the importance of retrieval-specific rewards that could directly improve the quality of the retrieval process itself.</li>
                    </ul>
                  </p>
              </div>
  
          </div>
      </div>

    </div>
    <!--/ Limitatoins. -->

  </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">

    <!-- Method. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-2">Method</h2>

        <!-- Paradigm. -->
        <h3 class="title is-4">The Search-and-Refine-During-Think Paradigm</h3>
        <div class="columns is-centered">
          <div class="column is-full-width">
            <div class="content has-text-justified">
              <img class="columns is-centered has-text-centered framework" src="./static/images/grpo.jpg" alt="Paradigm" width="100%" style="margin:0 auto">
              <br>
              <p>
                At the core of AutoRefine is a novel "search-and-refine-during-think" paradigm that extends the traditional "search-during-think" approach. This paradigm allows the LLM to:
                <ul>
                  <li><b>Think:</b> Reason about the problem and identify knowledge gaps.</li>
                  <li><b>Search:</b> Formulate queries to retrieve relevant information.</li>
                  <li><b>Receive Documents:</b> Obtain documents from an external knowledge source.</li>
                  <li><b>Refine:</b> Distill and extract key information from retrieved documents.</li>
                </ul>
                This cycle can repeat multiple times until the model has gathered sufficient information to confidently answer the question.
              </p>
            </div>
            
          </div>
        </div>
        <!-- Paradigm. -->
        
        <!-- Reward. -->
        <h3 class="title is-4">Reward Modeling with Retrieval-Aware Signals</h3>
        <div class="columns is-centered">
          <div class="column is-full-width">
              <div class="content has-text-justified">
                  <br>
                  <p>
                    AutoRefine employs a sophisticated reward system that combines:
                    <ul>
                    <li>
                      <b>Outcome-Based Reward:</b> This measures the correctness of the final answer using metrics like F1-score.
                    </li>
                    <li>
                      <b>Retrieval-Specific Reward:</b> This evaluates the quality of refined knowledge based on how well it captures essential information from the retrieved documents.
                    </li>
                    </ul>
                  </p>
              </div>
          </div>
        </div>
        <!--/ Reward. -->
      </div>
    </div>
    <!--/ Method. -->

  </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">

    <!-- Results. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-2">Experimental Results</h2>


        <!-- Overall Performance. -->
        <h3 class="title is-4">Overall Performance</h3>
        <div class="columns is-centered">
          <div class="column is-full-width">
              <div class="content has-text-justified">
                  <br>
                  <p>
                    AutoRefine was evaluated on seven question-answering benchmarks, including three single-hop datasets (NQ, TriviaQA, and PopQA) and four multi-hop datasets (HotpotQA, 2WikiMultihopQA, MuSiQue, and Bamboogle). The results demonstrate that:
                    <ul>
                    <li>
                      <b>AutoRefine significantly outperforms existing methods,</b> achieving 6.9% higher average accuracy than the strongest baseline across all benchmarks.
                    </li>
                    <li>
                      <b>The model shows particularly strong performance on multi-hop QA tasks,</b> demonstrating its ability to effectively handle complex reasoning that requires multiple pieces of information.
                    </li>
                    <img class="columns is-centered has-text-centered framework" src="./static/images/main_results.jpg" alt="Overall Performance" width="100%" style="margin:0 auto">
                    <li>
                      <b>The search frequency increases during training,</b> especially for multi-hop questions, showing that the model learns to perform more searches when dealing with complex queries.
                    </li>
                    <img class="columns is-centered has-text-centered framework" src="./static/images/search_behavior.jpg" alt="Search Behavior" width="100%" style="margin:0 auto">
                    <li>
                      <b>The refinement process successfully extracts crucial information from retrieved documents</b>.
                    </li>
                    <img class="columns is-centered has-text-centered framework" src="./static/images/refine_behavior.jpg" alt="Refine Behavior" width="100%" style="margin:0 auto">
                    </ul>
                  </p>
              </div>
          </div>
        </div>
        <!--/ Overall Performance. -->
        
        <!-- Ablation Study. -->
        <h3 class="title is-4">Ablation Study</h3>
        <div class="columns is-centered">
          <div class="column is-full-width">
              <div class="content has-text-justified">
                  <br>
                  <p>
                    <ul>
                    <li>
                      AutoRefine maintains high performance across different retrieval depths (number of documents retrieved per search), with the best results achieved at k=5.
                    </li>
                    <img class="columns is-centered has-text-centered framework" src="./static/images/ablation.jpg" alt="Ablation" width="50%" style="margin:0 auto">
                    <li>
                      Models trained with retrieval-specific rewards show improved search frequency, search quality, and refinement quality compared to models trained with only outcome-based rewards.
                    </li>
                    <img class="columns is-centered has-text-centered framework" src="./static/images/ablation.jpg" alt="Ablation" width="100%" style="margin:0 auto">
                    </ul>
                  </p>
              </div>
          </div>
        </div>
        <!--/ Ablation Study. -->
      </div>
      </div>
    </div>
    <!--/ Results. -->

  </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Related Links. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Acknowledgements</h2>

        <div class="content has-text-justified">
          <p>
            This project is built upon the foundational work of <a href="https://github.com/volcengine/verl">VeRL</a> and <a href="https://github.com/PeterGriffinJin/Search-R1">Search-R1</a>. We sincerely thank the authors of these projects for their valuable contributions, which have significantly supported and inspired our work.
          </p>
        </div>
      </div>
    </div>
    <!--/ Related Links. -->
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">Citation</h2>
    <pre><code>@article{shi2025search,
      title={Search and Refine During Think: Autonomous Retrieval-Augmented Reasoning of LLMs},
      author={Shi, Yaorui and Li, Shihan and Wu, Chang and Liu, Zhiyuan and Fang, Junfeng and Cai, Hengxing and Zhang, An and Wang, Xiang},
      journal={arXiv preprint arXiv:2505.11277},
      year={2025}
    }</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
      <div class="columns is-centered">
          <div class="column is-8">
              <div class="content">
                  <p style="text-align: center;">
                      The webpage is built based on <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
                  </p>
              </div>
          </div>
      </div>
  </div>
</footer>

</body>
</html>
